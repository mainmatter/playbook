# Full Service Project Flow

In Full Service projects, we guide clients through an entire project, solving
their business problems with bespoke digital products. This encompasses several
stages:

- identifying and understanding the nature of the problem as well as its
  implications
- conceptualising a software system that solves the previously identified
  problem(s)
- implementing that system and launching it
- validating that the product indeed solves the problems as expected

These stages will usually be passed through several times. In the first pass, we
try and build the minimal version of the system that solves the most pressing
problem(s). Subsequent passes each extend the system incrementally, potentially
addressing new learning gathered during the validation phase of the previous
pass.

## Definition

In the definition stage of a project, we work closely with the client in order
to understand the business problem and the implications it has. The nature of
the problem that needs to be addressed is often not obvious and we apply

## Conception

Once the problem has been identified and is well understood by all project
stakeholders we will look at defining a suitable solution that solves the
problem in the most effective and efficient way. That includes identifying the
target audience, their goals and motivations as well as the main features and
flows of the system to be built.

We will define each feature

### Scoping

For each pass, we will define a scope, explicitly defining the features and flows that will be included in the respective pass, as well as the ones that will not be included. Software projects are highly dynamic in nature and the reality is that only one of scope or time and budget can be fixed. By limiting the scope per iteration we minimize that dynamic and the associated risk.

Having agreed on an ideal solution, it is time to decide how to organize the set
of features that make it up. The main goal of planning is to understand what it
takes to deliver a solution of the highest possible quality, on time, and
budget.

During planning, we think about whether time or scope is fixed for building this
feature set (the only one can be fixed); if time is fixed, we try and identify
aspects of the feature that could be scoped down if we have to later. We then
try and give the customer an outlook for steps and overall duration (this is an
estimate, not a deadline).

The design and the list of documents that came out of the user journeys step are
the foundation for the implementation phase. Of course, they can change any
time, but it's what we start with. <We could give this a name, e.g., the
"bundle" or whatever>.

## Execution

The implementation phase combines both executing the design and developing the
features in code. All of the work should be tracked on the same board, following
our iteration approach we're already using and that's described in other section
of this playbook.

In the first pass of the project, this could mean that engineering can only
start with a slight delay as the designers need to prepare enough wireframes, so
the engineers are not blocked. We do our normal iterations-based process and
planning, creating specific issues based on them that we bundled in the planning
step.

During implementation, we keep a staging system updated so all stakeholders can
follow along the process. We ask our clients to join the iteration meetings ().
We will build slices of the system at once, that is the design, backend, and
frontend code of something so we can release these three things together. This
way, we can be sure they work together and move on to the next slice (see 
[basecamp.com/shapeup/3.2-chapter-10][integrating] for a good explanation).

[integrating]:
  https://basecamp.com/shapeup/3.2-chapter-10#integrating-in-one-place

### Launch

Post-launch we can operate the system for the client and potentially also
validate what we built works for users. Ideally, we'd be able to do this after
every pass of the full-service phase.

## Validation

Let's include something about user interview or similar mechanisms  **after
release** - a validation step in which we ensure that what we built is actually
what users want.

**Testing with users**

Data analysis and survey methods can be used to determine a potential subset of
users that would be most representative for testing. In this way, we can gather
more valuable insights and feedback.

We would outline the right survey method to recruit potential test users,
qualify them, and design the experiments.

## Iteration
